{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import string\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the password files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass1 = open(\"passwords1.txt\").read().splitlines()\n",
    "pass2 = open(\"passwords2.txt\").read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the 2 hash functions to be used:\n",
    "\n",
    "Method: For each existing string character i assign a value going from 0 to n (number of characters). Then i perform some transformations to make the hashes random. I finally mod with a prime number to minimise collisions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myhash1(s):\n",
    "   \n",
    "    a = string.printable\n",
    "    lst = []\n",
    "    for i in a:\n",
    "        lst.append(i)  \n",
    "        \n",
    "    encoder = []\n",
    "    for j in range(len(lst)):\n",
    "        encoder.append(int((((j+100)**2)*5059)+47))\n",
    "            \n",
    "\n",
    "    keys= lst\n",
    "    values= encoder\n",
    "    dictionary = dict(zip(keys, values))\n",
    "   \n",
    "    empty= []\n",
    "    for e in s:\n",
    "        empty.append(dictionary.get(e))\n",
    "    str1 =  int(''.join(map(str, empty)))\n",
    "    return str1%861259057\n",
    "\n",
    "def myhash2(s):\n",
    "    \n",
    "    a = string.printable\n",
    "    lst = []\n",
    "    for i in a:\n",
    "        lst.append(i)  \n",
    "        \n",
    "    encoder = []\n",
    "    for j in range(len(lst)):\n",
    "        encoder.append(int(10 + ((j+100)**(3/2))*67))\n",
    "            \n",
    "\n",
    "    keys= lst\n",
    "    values= encoder\n",
    "    dictionary = dict(zip(keys, values))\n",
    "   \n",
    "    empty= []\n",
    "    for e in s:\n",
    "        empty.append(dictionary.get(e))\n",
    "    str1 =  int(''.join(map(str, empty)))\n",
    "    return str1%853969703"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashing passwords. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running time note: I believe the hashing of the passwords should not be included in the bloom filter function since most passwords are stored in their hash equivalent and also hashing the whole database 1 time over actually takes a very long time.\n",
    "The running time of my hash functions is between 0.0006 and 0.0008 per string. Total strings to hash are more than 100 million, with 2 hashes this takes about 6 to 8 hours. Hence the actual bloom filter will be used on the list of already hashed passwords. Since the hash function was changed the new hashlists are based on a cut dataset to speed up running time without losing the logic of the filter. A prediction on running time for the whole dataset will be made at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass1 = pass1[:1000000]\n",
    "pass2 = pass2[:390000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hashing existing passwords: passwords1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash1p1 = [myhash1(str(pass1[i])) for i in range(len(pass1))]\n",
    "hash2p1 = [myhash2(str(pass1[i])) for i in range(len(pass1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hashing all the possible new passwords: passwords2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash1p2 = [myhash1(str(pass2[i])) for i in range(len(pass2))]\n",
    "hash2p2 = [myhash2(str(pass2[i])) for i in range(len(pass2))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hashes look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[368678279, 188403858, 707803710, 105061637, 269377512, 423937066, 6527838, 673589225, 12503355, 278690290]\n"
     ]
    }
   ],
   "source": [
    "print(hash1p1[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bloom Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the bloom filter which is initially a containter list of all 0s. Length based on range of all possible hashes, determined by largest prime used in modding the hashes string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BloomFilter():\n",
    "    start = time.time()\n",
    "    bf0 = [0]*861259057\n",
    "\n",
    "#Joining the lists(set union) of the 2 hash functions applied to the existing passwords(passwords1)\n",
    "    hashlist = [hash1p1,hash2p1]\n",
    "    listunion =  list(set().union(*hashlist))\n",
    "    L = len(listunion)\n",
    "\n",
    "\n",
    "#Filling in the bloom filter with 1 for every index that was created from hash functions\n",
    "    for i in range(L):\n",
    "        bf0[listunion[i]] = 1\n",
    "\n",
    "#Now we have to see if the possible new passwords already exist according to out bloom filter.\n",
    "    \n",
    "    newhashlist = [hash1p2,hash2p2]\n",
    "\n",
    "#Now I creat a yesno list saying if the potential new passwords exist or not, if both has indexes in the bloom filter equal 1, then exists, else they don't.\n",
    "\n",
    "    yesno= []\n",
    "    for i in range(len(hash1p2)):\n",
    "        if bf0[newhashlist[0][i]] == 1 and bf0[newhashlist[1][i] == 1]:\n",
    "            yesno.append(1)\n",
    "        else:\n",
    "            yesno.append(0)\n",
    "    end = time.time()\n",
    "    \n",
    "#To calculate the probability of false positives i reference this source: https://tsapps.nist.gov/publication/get_pdf.cfm?pub_id=903775\n",
    "  #and use Bloom's classical formulae for the false positive rate.\n",
    "\n",
    "    m = 861259057#Length of bloom filter\n",
    "    k = 2 #Number of hash functions used\n",
    "    n = 1000000 #objects mapped in bloom filter(passwords1)\n",
    "    p = (1-((1-1/m)**(k*n)))**k\n",
    "  \n",
    "    print('Number of hash function used: ', 2)\n",
    "    print('Number of duplicates detected: ', sum(yesno))\n",
    "    print('Probability of false positives: ', p)\n",
    "    print('Execution time: ', end-start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloom Filter steps:\n",
    "\n",
    "1 - Initialising filter\n",
    "2 - Joining the lists(set union) of the 2 hash functions applied to the existing passwords(passwords1)\n",
    "3 - Filling the bloom filter with each index found by both hash functions\n",
    "4 - Creating another list containing the prediction of our bloom filter\n",
    "5 - Filling this list with 1s if both hashes of possible new passwords exist in bloom filter, 0 otherwise. 1 in \"yesno\" list means password from password2 database probably exists in password1 database already, 0 means password for sure does not exist.\n",
    "\n",
    "\n",
    "Probability of false positives (FPR)\n",
    "To calculate the probability of false positives i reference this source: https://tsapps.nist.gov/publication/get_pdf.cfm?pub_id=903775\n",
    "I use Bloom's classical formulae for FPR. This underestimates the actual FPR of my bloom filter as proved in the paper but more accurate formulaes provided in the paper are computationally inefficient if not impossible with large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BloomFilter Output/Final Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hash function used:  2\n",
      "Number of duplicates detected:  0\n",
      "Probability of false positives:  5.380022741846551e-06\n",
      "Execution time:  6.916478872299194\n"
     ]
    }
   ],
   "source": [
    "BloomFilter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicates were detected which is actually to be expected given the password datasets are made up of randomized 20 character strings.\n",
    "Execution time on whole dataset which is 100 times larger is expected to be about 100 times larger since BloomFilter() is O(n). Therefore execution time would be around 400-700 seconds (guess of the average execition times)/ between 6 and 12 minutes on this particular machine. This particular bloom filter has a really low theoretical probability of false positives. Therefore the size of the filter could be reduced to lower execution time because the probability of false positives would still be low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exact number of false positives I have found is 0 since i detected 0 duplicates. If I did detect a duplicate I would find the index of the duplicate detected from hashing, find its corresponding string representation (the actual password from passwords2.txt file) and then I would run a search through the first database \"passwords1.txt\" and see if there is actually a match. If there is not then I would count that as a false positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
