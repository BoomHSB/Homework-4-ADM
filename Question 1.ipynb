{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import string\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the password files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "passwords1 = open(r\"/Users/marcodicio/Desktop/Marco/DATA/passwords1.txt\").read().splitlines()\n",
    "passwords2 = open(r\"/Users/marcodicio/Desktop/Marco/DATA/passwords2.txt\").read().splitlines()\n",
    "pass1 = passwords1\n",
    "pass2 = passwords2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the 2 hash functions to be used:\n",
    "\n",
    "Method: For each existing string character i assign a value going from 0 to n (number of characters). Then i perform some transformations to make the hashes random. I finally mod with a prime number to minimise collisions and make hashes of similar length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myhash1(s):\n",
    "   \n",
    "    a = string.printable\n",
    "    lst = []\n",
    "    for i in a:\n",
    "        lst.append(i)  \n",
    "        \n",
    "    encoder = []\n",
    "    for j in range(len(lst)):\n",
    "        encoder.append(int((((j+100)**2)*5059)+47))\n",
    "            \n",
    "\n",
    "    keys= lst\n",
    "    values= encoder\n",
    "    dictionary = dict(zip(keys, values))\n",
    "   \n",
    "    empty= []\n",
    "    for e in s:\n",
    "        empty.append(dictionary.get(e))\n",
    "    str1 =  int(''.join(map(str, empty)))\n",
    "    return str1%8114217931\n",
    "\n",
    "def myhash2(s):\n",
    "    \n",
    "    a = string.printable\n",
    "    lst = []\n",
    "    for i in a:\n",
    "        lst.append(i)  \n",
    "        \n",
    "    encoder = []\n",
    "    for j in range(len(lst)):\n",
    "        encoder.append(int(10 + ((j+100)**(3/2))*67))\n",
    "            \n",
    "\n",
    "    keys= lst\n",
    "    values= encoder\n",
    "    dictionary = dict(zip(keys, values))\n",
    "   \n",
    "    empty= []\n",
    "    for e in s:\n",
    "        empty.append(dictionary.get(e))\n",
    "    str1 =  int(''.join(map(str, empty)))\n",
    "    return str1%7076121391"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashing passwords. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running time note: I believe the hashing of the passwords should not be included in the bloom filter function since most passwords are stored in their hash equivalent and also hashing the whole database 1 time over actually takes a very long time.\n",
    "The running time of my hash functions is between 0.0006 and 0.0008 per string. Total strings to hash are more than 100 million, with 2 hashes this takes about 6 to 8 hours. Hence the actual bloom filter will be used on the list of already hashed passwords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hashing existing passwords: passwords1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash1p1 = [myhash1(str(pass1[i])) for i in range(len(pass1))]\n",
    "hash2p1 = [myhash2(str(pass1[i])) for i in range(len(pass1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hashing all the possible new passwords: passwords2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash1p2 = [myhash1(str(pass2[i])) for i in range(len(pass2))]\n",
    "hash2p2 = [myhash2(str(pass2[i])) for i in range(len(pass2))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bloom Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the bloom filter which is initially a containter list of all 0s. Length based on range of all possible hashes, determined by largest prime used in modding the hashes string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BloomFilter(pass1,pass2):\n",
    "    start = time.time()\n",
    "    \n",
    "    bf0 = [0]*8114217931\n",
    "    hashlist = [hash1p1,hash2p1]\n",
    "    listunion =  list(set().union(*hashlist))\n",
    "    L = len(listunion)\n",
    "    for i in range(L):\n",
    "        bf0[listunion[i]] = 1\n",
    "    newhashlist = [hash1p2,hash2p2]\n",
    "    yesno= []\n",
    "    for i in range(len(hash1p2)):\n",
    "        if bf0[newhashlist[0][i]] == 1 and bf0[newhashlist[1][i] == 1]:\n",
    "            yesno.append(1)\n",
    "        else:\n",
    "            yesno.append(0)\n",
    "    end = time.time()\n",
    "    \n",
    "    \n",
    "    #Printing question answers\n",
    "    \n",
    "    m = 8114217931#Length of bloom filter\n",
    "    k = 2 #Number of hash functions used\n",
    "    n = 100000000 #objects mapped in bloom filter(passwords1)\n",
    "    p = (1-((1-1/m)**(k*n)))**k\n",
    "  \n",
    "    print('Number of hash function used: ', 2)\n",
    "    print('Number of duplicates detected: ', sum(yesno))\n",
    "    print('Probability of false positives: ', p)\n",
    "    print('Execution time: ', end-start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloom Filter steps:\n",
    "\n",
    "1 - Initialising filter\n",
    "2 - Joining the lists(set union) of the 2 hash functions applied to the existing passwords(passwords1)\n",
    "3 - Filling the bloom filter with each index found by both hash functions\n",
    "4 - Creating another list containing the prediction of our bloom filter\n",
    "5 - Filling this list with 1s if both hashes of possible new passwords exist in bloom filter, 0 otherwise. 1 in \"yesno\" list means password from password2 database probably exists in password1 database already, 0 means password for sure does not exist.\n",
    "\n",
    "\n",
    "Probability of false positives (FPR)\n",
    "To calculate the probability of false positives i reference this source: https://tsapps.nist.gov/publication/get_pdf.cfm?pub_id=903775\n",
    "I use Bloom's classical formulae for FPR. This underestimates the actual FPR of my bloom filter as proved in the paper but more accurate formulaes provided in the paper are computationally inefficient if not impossible with large datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
